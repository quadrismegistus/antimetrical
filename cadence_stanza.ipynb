{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecd93b1-4a57-4717-921d-fba48d082c2c",
   "metadata": {},
   "source": [
    "# Developing text objects further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d458e262-ffb6-4df5-a819-36328b99ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,'/Users/ryan/github/cadence/')\n",
    "from cadence.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "652013e9-44e0-4a25-8986-b314b8fa78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Turning and turning in the widening gyre'\n",
    "txt=\"\"\"\n",
    "Turning and turning in the widening gyre  , the falcon cannot hear the falconer.\n",
    "Things fall apart; the centre cannot hold.\n",
    "\n",
    "Mere anarchy is loosed upon the world. \n",
    "The blood-dimmed tide is loosed, and everywhere the ceremony of innocence is drowned;\n",
    "The best lack all conviction, while the worst   \n",
    "Are full of passionate intensity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "aa3c26fc-6f8d-4de4-966d-98ece553bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='''The best lack all conviction,\n",
    "while the worst Are full of passionate intensity.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "cfdeed73-8265-47d2-acac-a6b772d1bfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 20:52:07 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| lemma        | combined |\n",
      "| depparse     | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| lemma        | combined |\n",
      "| depparse     | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-01-06 20:52:07 INFO: Use device: cpu\n",
      "INFO:stanza:Use device: cpu\n",
      "2022-01-06 20:52:07 INFO: Loading: tokenize\n",
      "INFO:stanza:Loading: tokenize\n",
      "2022-01-06 20:52:07 INFO: Loading: pos\n",
      "INFO:stanza:Loading: pos\n",
      "2022-01-06 20:52:07 INFO: Loading: lemma\n",
      "INFO:stanza:Loading: lemma\n",
      "2022-01-06 20:52:07 INFO: Loading: depparse\n",
      "INFO:stanza:Loading: depparse\n",
      "2022-01-06 20:52:08 INFO: Loading: constituency\n",
      "INFO:stanza:Loading: constituency\n",
      "2022-01-06 20:52:08 INFO: Done loading processors!\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The best lack all conviction,\\nwhile the worst Are full of passionate intensity.'"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stanza\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,lemma,depparse,constituency')\n",
    "doc = nlp(s)\n",
    "sent = doc.sentences[0]\n",
    "tree = sentence.constituency\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "03971b74-ee32-4c01-8e14-e57f8d1e17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPD={}\n",
    "\n",
    "def get_nlp(**kwargs):\n",
    "    global NLPD\n",
    "    key=kwargs_key(kwargs)\n",
    "    if not key in NLPD:\n",
    "        import stanza\n",
    "        NLPD[key] = stanza.Pipeline(**kwargs)\n",
    "    return NLPD[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0d258fff-1c95-4d0d-9a71-fc231cf569c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recurse_tree(tree,node_i=0,path=[]):\n",
    "    o=[]\n",
    "    if not hasattr(tree,'node_i'):\n",
    "        tree.node_i=node_i\n",
    "        node_i+=1\n",
    "    if not tree.is_leaf():\n",
    "        path+=[f'{tree.node_i}-{tree.label}']\n",
    "        for x in tree.children:\n",
    "            o+=recurse_tree(x,node_i=node_i,path=list(path))\n",
    "    else:\n",
    "        o+=[tuple(path)]\n",
    "        path=[]\n",
    "    return o\n",
    "\n",
    "\n",
    "def tokenize_nlp_iter(txt,lang=DEFAULT_LANG,engine='',sep_line=SEP_LINE, sep_para=SEP_STANZA, seps_phrase=SEPS_PHRASE):\n",
    "    proc='tokenize,pos,lemma,depparse,constituency'\n",
    "    badcols={'feats','start_char','end_char','id'}\n",
    "    nlp=get_nlp(lang=lang, processors=proc)\n",
    "    \n",
    "    char_i=0\n",
    "    para_i=1\n",
    "    line_i=1\n",
    "    linepart_i=1\n",
    "    linepart_ii=0\n",
    "        \n",
    "    doc=nlp(txt)\n",
    "    for sent_i, sent in enumerate(doc.sentences):\n",
    "        senttree = recurse_tree(sent.constituency, node_i=0, path=[])\n",
    "        for tok_i,tok in enumerate(sent.tokens):\n",
    "            prefstr=txt[char_i:tok.start_char]\n",
    "            tokstr=txt[tok.start_char : tok.end_char]\n",
    "            realtok=txt[char_i:tok.end_char]\n",
    "            if sep_para in prefstr: para_i+=1\n",
    "            if sep_line in prefstr: line_i+=1\n",
    "            char_i=tok.end_char\n",
    "            tokd=tok.to_dict()[0]\n",
    "            word_i=tok_i+1\n",
    "            assert tok.id[0]==word_i\n",
    "            \n",
    "            odx_tokd=dict((k,v) for k,v in tokd.items() if k not in badcols)\n",
    "            \n",
    "            odx_feat={}\n",
    "            for feat in tokd.get('feats','').split('|'):\n",
    "                if not feat: continue\n",
    "                fk,fv=feat.split('=',1)\n",
    "                odx_feat[fk]=fv\n",
    "                \n",
    "            odx_const=dict(\n",
    "                depth=len(senttree[tok_i]),\n",
    "                constituency='('+'('.join(senttree[tok_i])+'('\n",
    "            )\n",
    "            \n",
    "            odx=dict(\n",
    "                para_i=para_i,\n",
    "                sent_i=sent_i+1,\n",
    "                linepart_i=linepart_i,\n",
    "                line_i=line_i,\n",
    "                word_i=tok_i+1,\n",
    "                word_pref=prefstr,\n",
    "                word=tokstr,\n",
    "                **odx_tokd,\n",
    "                **odx_const,\n",
    "                **odx_feat,\n",
    "            )\n",
    "            \n",
    "            \n",
    "            yield odx\n",
    "            \n",
    "            if set(realtok)&set(seps_phrase): linepart_i+=1\n",
    "\n",
    "def tokenize_nlp(txt,**kwargs):\n",
    "    odf=pd.DataFrame(tokenize_nlp_iter(txt)).fillna('')\n",
    "    return odf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e92ae5-0178-41a5-9319-412e0c652a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "9ac3f652-4ca7-48ef-b665-ceaac8bdedb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 20:52:13 INFO: Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| lemma        | combined |\n",
      "| depparse     | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "INFO:stanza:Loading these models for language: en (English):\n",
      "===========================\n",
      "| Processor    | Package  |\n",
      "---------------------------\n",
      "| tokenize     | combined |\n",
      "| pos          | combined |\n",
      "| lemma        | combined |\n",
      "| depparse     | combined |\n",
      "| constituency | wsj      |\n",
      "===========================\n",
      "\n",
      "2022-01-06 20:52:13 INFO: Use device: cpu\n",
      "INFO:stanza:Use device: cpu\n",
      "2022-01-06 20:52:13 INFO: Loading: tokenize\n",
      "INFO:stanza:Loading: tokenize\n",
      "2022-01-06 20:52:13 INFO: Loading: pos\n",
      "INFO:stanza:Loading: pos\n",
      "2022-01-06 20:52:13 INFO: Loading: lemma\n",
      "INFO:stanza:Loading: lemma\n",
      "2022-01-06 20:52:13 INFO: Loading: depparse\n",
      "INFO:stanza:Loading: depparse\n",
      "2022-01-06 20:52:13 INFO: Loading: constituency\n",
      "INFO:stanza:Loading: constituency\n",
      "2022-01-06 20:52:13 INFO: Done loading processors!\n",
      "INFO:stanza:Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_i</th>\n",
       "      <th>sent_i</th>\n",
       "      <th>linepart_i</th>\n",
       "      <th>line_i</th>\n",
       "      <th>word_i</th>\n",
       "      <th>word_pref</th>\n",
       "      <th>word</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>upos</th>\n",
       "      <th>xpos</th>\n",
       "      <th>head</th>\n",
       "      <th>deprel</th>\n",
       "      <th>depth</th>\n",
       "      <th>constituency</th>\n",
       "      <th>Definite</th>\n",
       "      <th>PronType</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Number</th>\n",
       "      <th>Mood</th>\n",
       "      <th>Tense</th>\n",
       "      <th>VerbForm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>3</td>\n",
       "      <td>det</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-NP(3-DT(</td>\n",
       "      <td>Def</td>\n",
       "      <td>Art</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>best</td>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>3</td>\n",
       "      <td>amod</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-NP(3-JJS(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sup</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>lack</td>\n",
       "      <td>lack</td>\n",
       "      <td>lack</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>5</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-NP(3-NN(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>5</td>\n",
       "      <td>det</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-NP(3-DT(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>conviction</td>\n",
       "      <td>conviction</td>\n",
       "      <td>conviction</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-NP(3-NN(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>11</td>\n",
       "      <td>punct</td>\n",
       "      <td>3</td>\n",
       "      <td>(0-ROOT(1-S(2-,(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>\\n</td>\n",
       "      <td>while</td>\n",
       "      <td>while</td>\n",
       "      <td>while</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>11</td>\n",
       "      <td>mark</td>\n",
       "      <td>4</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-IN(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>9</td>\n",
       "      <td>det</td>\n",
       "      <td>6</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-NP(5-DT(</td>\n",
       "      <td>Def</td>\n",
       "      <td>Art</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>worst</td>\n",
       "      <td>worst</td>\n",
       "      <td>bad</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJS</td>\n",
       "      <td>11</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>6</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-NP(5-JJS(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sup</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>Are</td>\n",
       "      <td>Are</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>11</td>\n",
       "      <td>cop</td>\n",
       "      <td>6</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-VP(5-VBP(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ind</td>\n",
       "      <td>Pres</td>\n",
       "      <td>Fin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>5</td>\n",
       "      <td>advcl</td>\n",
       "      <td>7</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-VP(5-ADJP(6-JJ(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pos</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>14</td>\n",
       "      <td>case</td>\n",
       "      <td>8</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-VP(5-ADJP(6-PP(7-IN(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td></td>\n",
       "      <td>passionate</td>\n",
       "      <td>passionate</td>\n",
       "      <td>passionate</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>14</td>\n",
       "      <td>amod</td>\n",
       "      <td>9</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-VP(5-ADJP(6-PP(7-NP(8...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pos</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>intensity</td>\n",
       "      <td>intensity</td>\n",
       "      <td>intensity</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>11</td>\n",
       "      <td>obl</td>\n",
       "      <td>9</td>\n",
       "      <td>(0-ROOT(1-S(2-SBAR(3-S(4-VP(5-ADJP(6-PP(7-NP(8...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Sing</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "      <td>punct</td>\n",
       "      <td>3</td>\n",
       "      <td>(0-ROOT(1-S(2-.(</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    para_i  sent_i  linepart_i  line_i  ...  Number Mood Tense VerbForm\n",
       "0        1       1           1       1  ...                            \n",
       "1        1       1           1       1  ...                            \n",
       "2        1       1           1       1  ...    Sing                    \n",
       "3        1       1           1       1  ...                            \n",
       "4        1       1           1       1  ...    Sing                    \n",
       "5        1       1           1       1  ...                            \n",
       "6        1       1           2       2  ...                            \n",
       "7        1       1           2       2  ...                            \n",
       "8        1       1           2       2  ...                            \n",
       "9        1       1           2       2  ...          Ind  Pres      Fin\n",
       "10       1       1           2       2  ...                            \n",
       "11       1       1           2       2  ...                            \n",
       "12       1       1           2       2  ...                            \n",
       "13       1       1           2       2  ...    Sing                    \n",
       "14       1       1           2       2  ...                            \n",
       "\n",
       "[15 rows x 22 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_nlp(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0532021-5db1-4800-9d55-3e854e7d45eb",
   "metadata": {},
   "source": [
    "### Metrical tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "63360b31-5f90-486b-9295-048cdb9af8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtree_str(sent):\n",
    "    o=[]\n",
    "    for dep in sent.dependencies:\n",
    "        w1,rel,w2=dep\n",
    "        ostr=f'{rel}({w1.text}-{w1.id}, {w2.text}-{w2.id})'\n",
    "        o+=[ostr]\n",
    "    return '\\n'.join(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "c7c5d85a-4d6d-43af-96fd-297f0788d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metricaltree import DependencyTree,MetricalTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "fd07fef4-edec-41b8-8e6e-6284a67d7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ctree_str(sent):\n",
    "    return str(sent.constituency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "d6c80e59-8626-4c9a-acd9-a19c8f8ba26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(ROOT (S (NP (DT The) (JJS best) (NN lack)) (NP (DT all) (NN conviction)) (, ,) (SBAR (IN while) (S (NP (DT the) (JJS worst)) (VP (VBP Are) (ADJP (JJ full) (PP (IN of) (NP (JJ passionate) (NN intensity))))))) (. .)))'"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctree=get_ctree_str(sent)\n",
    "ctree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "f24cad7c-45d8-47c2-b9f1-2b0548d00300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'det(lack-3, The-1)\\namod(lack-3, best-2)\\nnsubj(conviction-5, lack-3)\\ndet(conviction-5, all-4)\\nroot(ROOT-0, conviction-5)\\npunct(full-11, ,-6)\\nmark(full-11, while-7)\\ndet(worst-9, the-8)\\nnsubj(full-11, worst-9)\\ncop(full-11, Are-10)\\nadvcl(conviction-5, full-11)\\ncase(intensity-14, of-12)\\namod(intensity-14, passionate-13)\\nobl(full-11, intensity-14)\\npunct(conviction-5, .-15)'"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree=get_dtree_str(sent)\n",
    "dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "d3cd9c96-1a8f-4ec8-8e46-d132eafab48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bothtree=ctree+'\\n\\n'+dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "e97869ea-edf4-4db9-846b-45abff315316",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk.compat' has no attribute 'string_types'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/jyzw5nyj1fnf0c_1czgsg2fc0000gn/T/ipykernel_59237/3417641982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbothtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mcTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdGraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mdTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mdTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mdeps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdGraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(cls, tree)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(cls, tree)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(cls, tree)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDependencyTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(cls, tree)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/prosodic/metricaltree/deptree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node, children, dep)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDependencyTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preterm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.compat' has no attribute 'string_types'"
     ]
    }
   ],
   "source": [
    "DependencyTree.fromstring(bothtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaca85-31bb-4ad2-a541-66e78cf25025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e322a00-363e-46dc-bdce-5f524f9d0d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1b3c5-2548-453a-a349-af793b92f7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802d908-34ed-4caf-b65f-d16138279fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c9e91-1bb7-4cda-b610-91b2a93fa5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53116c-9706-40f3-812a-21f1db91b50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43eb5284-555e-4ebe-80cb-d32ae2fa8dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nTurning and turning in the widening gyre.',\n",
       " 'the falcon cannot hear the falconer;\\nThings fall apart; the centre cannot hold;\\nMere anarchy is loosed upon the world.',\n",
       " 'The blood-dimmed tide is loosed, and everywhere the ceremony of innocence is drowned;\\nThe best lack all conviction, while the worst   \\nAre full of passionate intensity.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d0e8c6-97d5-4105-a3b1-a2c985feee39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7991df43-2d77-46af-b595-886df6126e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stanza_i': 1, 'line_i': 1, 'linepart_i': 1, 'linepart_str': 'hello world '}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lineparts_ld('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa8559-6cd9-4cb4-8178-3ff1fee5dee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cffba42b-96db-4520-9dd2-547799f17c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for odf in scan_iter(txt,max_len=2): display(odf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eccc3930-bdc6-4fbe-9911-f6626ec4a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning lines [x1]: 100%|███████████████████████████████████████████| 29/29 [00:00<00:00, 37.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_funcword</th>\n",
       "      <th>is_heavy</th>\n",
       "      <th>is_light</th>\n",
       "      <th>is_peak</th>\n",
       "      <th>is_stressed</th>\n",
       "      <th>is_trough</th>\n",
       "      <th>is_unstressed</th>\n",
       "      <th>linepart_num_monosyll</th>\n",
       "      <th>linepart_num_syll</th>\n",
       "      <th>prom_strength</th>\n",
       "      <th>prom_stress</th>\n",
       "      <th>prom_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanza_i</th>\n",
       "      <th>line_i</th>\n",
       "      <th>linepart_i</th>\n",
       "      <th>linepart_str</th>\n",
       "      <th>word_i</th>\n",
       "      <th>word_str</th>\n",
       "      <th>word_ipa_i</th>\n",
       "      <th>word_ipa</th>\n",
       "      <th>syll_i</th>\n",
       "      <th>syll_str</th>\n",
       "      <th>syll_ipa</th>\n",
       "      <th>syll_stress</th>\n",
       "      <th>syll_weight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">'tɛː.nɪŋ</th>\n",
       "      <th>1</th>\n",
       "      <th>Tur</th>\n",
       "      <th>'tɛː</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ning</th>\n",
       "      <th>nɪŋ</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">and turning</th>\n",
       "      <th>1</th>\n",
       "      <th>and</th>\n",
       "      <th>1</th>\n",
       "      <th>ænd</th>\n",
       "      <th>1</th>\n",
       "      <th>and</th>\n",
       "      <th>ænd</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">'tɛː.nɪŋ</th>\n",
       "      <th>1</th>\n",
       "      <th>tur</th>\n",
       "      <th>'tɛː</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ning</th>\n",
       "      <th>nɪŋ</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">29</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">passionate intensity.</th>\n",
       "      <th>1</th>\n",
       "      <th>passionate</th>\n",
       "      <th>1</th>\n",
       "      <th>'pæ.ʃə.nət</th>\n",
       "      <th>3</th>\n",
       "      <th>nate</th>\n",
       "      <th>nət</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">intensity.</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">ɪn.'tɛn.sə.tiː</th>\n",
       "      <th>1</th>\n",
       "      <th>in</th>\n",
       "      <th>ɪn</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ten</th>\n",
       "      <th>'tɛn</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>si</th>\n",
       "      <th>sə</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>ty.</th>\n",
       "      <th>tiː</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 is_funcword  ...  prom_weight\n",
       "stanza_i line_i linepart_i linepart_str           word_i word_str    word_ipa_i word_ipa       syll_i syll_str syll_ipa syll_stress syll_weight               ...             \n",
       "1        1      1          Turning                1      Turning     1          'tɛː.nɪŋ       1      Tur      'tɛː     P                                  0  ...          NaN\n",
       "                                                                                               2      ning     nɪŋ      U                                  0  ...          NaN\n",
       "                2          and turning            1      and         1          ænd            1      and      ænd      U                                  1  ...          NaN\n",
       "                                                  2      turning     1          'tɛː.nɪŋ       1      tur      'tɛː     P                                  0  ...          NaN\n",
       "                                                                                               2      ning     nɪŋ      U                                  0  ...          NaN\n",
       "...                                                                                                                                                      ...  ...          ...\n",
       "                29         passionate intensity.  1      passionate  1          'pæ.ʃə.nət     3      nate     nət      U                                  0  ...          NaN\n",
       "                                                  2      intensity.  1          ɪn.'tɛn.sə.tiː 1      in       ɪn       U                                  0  ...          NaN\n",
       "                                                                                               2      ten      'tɛn     P                                  0  ...          NaN\n",
       "                                                                                               3      si       sə       U                                  0  ...          NaN\n",
       "                                                                                               4      ty.      tiː      U                                  0  ...          NaN\n",
       "\n",
       "[93 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan(txt,max_len=2,linebreaks=True,phrasebreaks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34eea5c2-4ded-4302-8b61-72fc95e6797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Verse(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Poem(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Prose(txt,**kwargs):\n",
    "    kwargs={**dict(prose=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def FreeVerse(txt,**kwargs):\n",
    "    kwargs={**dict(linebreaks=True,phrasebreaks=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# loading txt/strings\n",
    "def to_fn_txt(txt_or_fn):\n",
    "    # load txt\n",
    "    if type(txt_or_fn)==str and not '\\n' in txt_or_fn and os.path.exists(txt_or_fn):\n",
    "        fn=txt_or_fn\n",
    "        with open(fn,encoding='utf-8',errors='replace') as f:\n",
    "            txt=f.read()\n",
    "    else:\n",
    "        fn=''\n",
    "        txt=txt_or_fn\n",
    "    return (fn,txt.strip())\n",
    "\n",
    "\n",
    "### convenient objs\n",
    "def kwargs_key(kwargs,bad_keys={'num_proc','progress','desc'}):\n",
    "    return ', '.join(\n",
    "        f'{k}={v}'\n",
    "        for k,v in kwargs.items()\n",
    "        if k not in bad_keys\n",
    "    )\n",
    "    \n",
    "    \n",
    "### texts\n",
    "class Text(object):\n",
    "    def __init__(self,txt_or_fn,**kwargs):\n",
    "        \n",
    "        self._scans={}\n",
    "        self._parses={}\n",
    "        self._lineparts={}\n",
    "        self._num_lines=None\n",
    "        self._num_stanzas=None\n",
    "        self._infod={}\n",
    "        self._kwargs=kwargs\n",
    "        \n",
    "        ## Load texts\n",
    "        self.fn,self.txt=to_fn_txt(txt_or_fn)\n",
    "        \n",
    "    # def __repr__(self):\n",
    "    #     o=self.txt.split('\\n\\n')[0] if self.txt is not None else \"\"\n",
    "    #     o='\\t' + '\\n\\t'.join(l for l in o.split('\\n'))\n",
    "    #     o=f'''<cadence.Text: {self.first_line} ({self.num_stanzas} stanza{\"s\" if self.num_stanzas>1 else \"\"}, {self.num_lines} line{\"s\" if self.num_lines>1 else \"\"})>'''.strip()\n",
    "    #     #o='\\n'.join(l.strip() for l in o.split('\\n'))\n",
    "    #     return o\n",
    "    \n",
    "    def kwargs(self,**kwargs):\n",
    "        return {**self._kwargs, **kwargs}\n",
    "    \n",
    "    def get_kwargs_key(self,**kwargs):\n",
    "        return kwargs_key(self.kwargs(**kwargs))\n",
    "\n",
    "\n",
    "    \n",
    "    ##################################################################\n",
    "    ### Stanzas\n",
    "    def stanzas(self,txt='',**kwargs):\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return to_stanzas_str(txt if txt else self.txt,**kwargs)    \n",
    "\n",
    "    ##################################################################\n",
    "    ### Lines\n",
    "    \n",
    "    def lines(self,txt='',linebreaks=False,prose=False,**kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        to_lines_now = to_lines_str if kwargs.get('linebreaks') or kwargs.get('verse') else to_sents_str\n",
    "        return [\n",
    "            l\n",
    "            for stanza_str in self.stanzas(txt,**kwargs)\n",
    "            for l in to_lines_now(stanza_str, **kwargs)\n",
    "        ]\n",
    "    \n",
    "    def sentences(self,txt='',**kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return [\n",
    "            lp\n",
    "            for line_str in self.lines(txt,**kwargs)\n",
    "            for lp in to_sents_str(line_str, **kwargs)\n",
    "        ]\n",
    "\n",
    "\n",
    "    ##################################################################\n",
    "    ### LINEPARTS\n",
    "    \n",
    "    ### Lineparts\n",
    "    def lineparts(self, txt='', **kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return [\n",
    "            lp\n",
    "            for line_str in self.lines(txt,**kwargs)\n",
    "            for lp in to_lineparts_str(line_str, **kwargs)\n",
    "        ]        \n",
    "    \n",
    "    ##################################################################\n",
    "    ### SCANS\n",
    "    \n",
    "    def scan(self, force=False, **kwargs):\n",
    "        key=self.get_kwargs_key(**kwargs)\n",
    "        if force or not key in self._scans:\n",
    "            self._scans[key]=scan(self.txt,**kwargs)\n",
    "        return self._scans[key]\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    ### PARSE\n",
    "    \n",
    "    def parse(self,\n",
    "            force=False,\n",
    "            verbose=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs['verbose']=verbose\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        if force or not (key_syll in self._parses) or (not key_line in self._parses):\n",
    "            self._parses[key_syll]=parse(self.txt, **kwargs_syll)\n",
    "            self._parses[key_line]=to_lines(self._parses[key_syll])\n",
    "        elif kwargs.get('verbose',True):\n",
    "            for li,linedf in sorted(self._parses[key_syll].reset_index().groupby(['stanza_i','line_i'])):\n",
    "                display(show_parse(linedf))\n",
    "\n",
    "        self.infod=info_parses(self._parses[key_line])\n",
    "        if verbose: printm(show_info_parses(self.infod))\n",
    "                \n",
    "        \n",
    "    def parses(self,\n",
    "            force=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs={**self.kwargs, **kwargs}\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        key=key_syll if kwargs.get('by_syll') else key_line\n",
    "        if not key in self._parses:\n",
    "            self.parse(force=force, **kwargs)\n",
    "        if not key in self._parses: return\n",
    "        \n",
    "        odf=self._parses[key]\n",
    "        if only_unbounded and ('parse_is_bounded' in set(odf.index.names) or 'parse_is_bounded' in set(odf.columns)):\n",
    "            #odf=odf[odf.parse_is_bounded==False]\n",
    "            odf=odf.query('parse_is_bounded==False')\n",
    "        if only_best and ('parse_rank' in set(odf.index.names) or 'parse_rank' in set(odf.columns)):\n",
    "            odf=odf.query('parse_rank==1')\n",
    "        \n",
    "        return odf\n",
    "\n",
    "    def best_parses(self, force=False, **kwargs):\n",
    "        return self.parses(force=force,only_best=True,**kwargs)\n",
    "    def all_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=False,**kwargs)\n",
    "    def unbounded_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e6dd0-8667-4d79-bff1-2a426e012df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6364c6-1e4e-4d10-948e-9a6f3fb40a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Text('saintsbury/txt/en.addison.prose.Saintsbury.psgs_quoted.txt', prose=True, test='hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd08d9a62951c4de3cec93df06e5a8769682e2513316501195b5ad08e283a24e7b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
