{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecd93b1-4a57-4717-921d-fba48d082c2c",
   "metadata": {},
   "source": [
    "# Developing text objects further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d458e262-ffb6-4df5-a819-36328b99ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,'/Users/ryan/github/cadence/')\n",
    "from cadence.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "652013e9-44e0-4a25-8986-b314b8fa78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Turning and turning in the widening gyre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc53116c-9706-40f3-812a-21f1db91b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_stanzas_str(full_txt,sep=SEP_STANZA,**kwargs):\n",
    "    return [st.strip() for st in full_txt.strip().split(sep) if st.strip()]\n",
    "\n",
    "def to_lines_str(stanza_txt,sep=SEP_STANZA,**kwargs):\n",
    "    return [st.strip() for st in stanza_txt.strip().split(sep) if st.strip()]\n",
    "\n",
    "def to_sents_str(stanza_txt,**kwargs):\n",
    "    return list(nltk.sent_tokenize(stanza_txt))\n",
    "\n",
    "def to_lineparts_str(line_str,seps=SEPS_PHRASE,min_len=1,max_len=15):\n",
    "    if min_len is None: min_len=1\n",
    "    if max_len is None: max_len=1000000000\n",
    "\n",
    "    o=[]\n",
    "    sentparts=[]\n",
    "    sentpart=[]\n",
    "    for token in tokenize_nice(line_str):\n",
    "        pref,tok,suf = split_punct(token)\n",
    "\n",
    "        # end prev?\n",
    "        if sentpart and set(pref)&set(seps) and len(sentpart)>=min_len:\n",
    "            sentparts.append(sentpart)\n",
    "            sentpart=[]\n",
    "\n",
    "        # add no matter what\n",
    "        sentpart.append(token)\n",
    "\n",
    "        # end after? or if too long?\n",
    "        if sentpart and ((set(suf)&set(seps) and len(sentpart)>=min_len) or len(sentpart)>=max_len):\n",
    "            sentparts.append(sentpart)\n",
    "            sentpart=[]\n",
    "            \n",
    "    # add if remaining\n",
    "    if sentpart:\n",
    "        sentparts.append(sentpart)\n",
    "        sentpart=[]\n",
    "    return [''.join(x) for x in sentparts]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def linepart(\n",
    "        txt_or_fn_or_lpdf,\n",
    "        lang=DEFAULT_LANG,\n",
    "        progress=True,\n",
    "        incl_alt=INCL_ALT,\n",
    "        num_proc=DEFAULT_NUM_PROC,\n",
    "        linebreaks=False,\n",
    "        phrasebreaks=True,\n",
    "        verse=None,\n",
    "        prose=None,\n",
    "        min_len=MIN_WORDS_IN_PHRASE,\n",
    "        max_len=MAX_WORDS_IN_PHRASE,\n",
    "        seps=SEPS_PHRASE,\n",
    "        desc='Iterating over line scansions',\n",
    "        **kwargs):\n",
    "    \n",
    "    if type(txt_or_fn_or_lpdf) == pd.DataFrame:\n",
    "        odf=resetindex(txt_or_fn_or_lpdf)\n",
    "        if 'linepart_str' in set(odf.columns):\n",
    "            return odf\n",
    "        else:\n",
    "            raise Exception('Input is neither string or a linepart-df [result of lineparts()]')\n",
    "    \n",
    "    full_txt=to_txt(txt_or_fn_or_lpdf)\n",
    "    if full_txt is None: return\n",
    "    \n",
    "    if verse==True or prose==False:\n",
    "        linebreaks=True\n",
    "        phrasebreaks=False\n",
    "    elif prose==True or verse==False:\n",
    "        linebreaks=False\n",
    "        phrasebreaks=True\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    dfl=[]\n",
    "    to_lines_now = to_lines_str if linebreaks else to_sents_str\n",
    "    kwargs['lang']=lang\n",
    "    kwargs['incl_alt']=incl_alt\n",
    "    \n",
    "        \n",
    "    objs=[\n",
    "        dict(\n",
    "            stanza_i=stanza_i+1,\n",
    "            line_i=line_i+1,\n",
    "            linepart_i=linepart_i+1,\n",
    "            linepart_str=linepart_txt\n",
    "        )\n",
    "        for stanza_i,stanza_txt in enumerate(to_stanzas_str(full_txt))\n",
    "        for line_i,line_txt in enumerate(to_lines_now(stanza_txt))\n",
    "        for linepart_i,linepart_txt in enumerate(\n",
    "            to_lineparts_str(\n",
    "                line_txt,\n",
    "                seps=seps,\n",
    "                min_len=min_len,\n",
    "                max_len=max_len\n",
    "            ) if phrasebreaks else [line_txt]\n",
    "        )\n",
    "    ]\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41fa8559-6cd9-4cb4-8178-3ff1fee5dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_iter(df_or_txt_or_fn,num_proc=1,lim=None,progress=True,lineparts_ld=[],**kwargs):\n",
    "    if not lineparts_ld:\n",
    "        lineparts_ld=linepart(df_or_txt_or_fn,**kwargs)\n",
    "    iterr_o=pmap_iter(\n",
    "        do_scan_iter,\n",
    "        lineparts_ld,\n",
    "        progress=progress,\n",
    "        num_proc=num_proc,\n",
    "        desc='Scanning lines'\n",
    "    )\n",
    "    for i,odf in enumerate(iterr_o):\n",
    "        if lim and i>=lim: break\n",
    "        yield odf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34eea5c2-4ded-4302-8b61-72fc95e6797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Verse(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Poem(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Prose(txt,**kwargs):\n",
    "    kwargs={**dict(prose=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def FreeVerse(txt,**kwargs):\n",
    "    kwargs={**dict(linebreaks=True,phrasebreaks=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# loading txt/strings\n",
    "def to_fn_txt(txt_or_fn):\n",
    "    # load txt\n",
    "    if type(txt_or_fn)==str and not '\\n' in txt_or_fn and os.path.exists(txt_or_fn):\n",
    "        fn=txt_or_fn\n",
    "        with open(fn,encoding='utf-8',errors='replace') as f:\n",
    "            txt=f.read()\n",
    "    else:\n",
    "        fn=''\n",
    "        txt=txt_or_fn\n",
    "    return (fn,txt.strip())\n",
    "\n",
    "\n",
    "### convenient objs\n",
    "def kwargs_key(kwargs,bad_keys={'num_proc','progress','desc'}):\n",
    "    return ', '.join(\n",
    "        f'{k}={v}'\n",
    "        for k,v in kwargs.items()\n",
    "        if k not in bad_keys\n",
    "    )\n",
    "    \n",
    "    \n",
    "### texts\n",
    "class Text(object):\n",
    "    def __init__(self,txt_or_fn,**kwargs):\n",
    "        \n",
    "        self._scans={}\n",
    "        self._parses={}\n",
    "        self._lineparts={}\n",
    "        self._num_lines=None\n",
    "        self._num_stanzas=None\n",
    "        self._infod={}\n",
    "        \n",
    "        ## Set kwargs\n",
    "        self.kwargs=kwargs\n",
    "        for k,v in self.kwargs.items(): setattr(self,k,v)\n",
    "        self.kwargs_key=kwargs_key(self.kwargs)\n",
    "        \n",
    "        ## Load texts\n",
    "        self.fn,self.txt=to_fn_txt(txt_or_fn)\n",
    "        \n",
    "    # def __repr__(self):\n",
    "    #     o=self.txt.split('\\n\\n')[0] if self.txt is not None else \"\"\n",
    "    #     o='\\t' + '\\n\\t'.join(l for l in o.split('\\n'))\n",
    "    #     o=f'''<cadence.Text: {self.first_line} ({self.num_stanzas} stanza{\"s\" if self.num_stanzas>1 else \"\"}, {self.num_lines} line{\"s\" if self.num_lines>1 else \"\"})>'''.strip()\n",
    "    #     #o='\\n'.join(l.strip() for l in o.split('\\n'))\n",
    "    #     return o\n",
    "    \n",
    "    def get_kwargs_key(self,**kwargs):\n",
    "        kwargs_both = {**self.kwargs, **kwargs}\n",
    "        return kwargs_key(kwargs_both)\n",
    "\n",
    "\n",
    "    \n",
    "    ##################################################################\n",
    "    ### Stanzas\n",
    "    def stanzas(self,txt=None,**kwargs):\n",
    "        return to_stanzas_str(self.txt if not txt else txt,**kwargs)    \n",
    "\n",
    "    ##################################################################\n",
    "    ### Lines\n",
    "    \n",
    "    def lines(self,txt=None,**kwargs):\n",
    "        if not stanza_str: stanza_str=self.txt\n",
    "        return to_lines_str(stanza_str, **kwargs)\n",
    "\n",
    "    ##################################################################\n",
    "    ### LINEPARTS\n",
    "    \n",
    "    ### Lineparts\n",
    "    def lineparts(self, **kwargs):\n",
    "        key=self.get_kwargs_key(**kwargs)\n",
    "        if force or not key in self._lineparts:\n",
    "            self._lineparts[key]=linepart(self.txt,**kwargs)\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    ### SCANS\n",
    "    \n",
    "    def scan(self, force=False, **kwargs):\n",
    "        key=self.get_kwargs_key(**kwargs)\n",
    "        if force or not key in self._scans:\n",
    "            self._scans[key]=scan(self.txt,**kwargs)\n",
    "        return self._scans[key]\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    ### PARSE\n",
    "    \n",
    "    def parse(self,\n",
    "            force=False,\n",
    "            verbose=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs['verbose']=verbose\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        if force or not (key_syll in self._parses) or (not key_line in self._parses):\n",
    "            self._parses[key_syll]=parse(self.txt, **kwargs_syll)\n",
    "            self._parses[key_line]=to_lines(self._parses[key_syll])\n",
    "        elif kwargs.get('verbose',True):\n",
    "            for li,linedf in sorted(self._parses[key_syll].reset_index().groupby(['stanza_i','line_i'])):\n",
    "                display(show_parse(linedf))\n",
    "\n",
    "        self.infod=info_parses(self._parses[key_line])\n",
    "        if verbose: printm(show_info_parses(self.infod))\n",
    "                \n",
    "        \n",
    "    def parses(self,\n",
    "            force=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs={**self.kwargs, **kwargs}\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        key=key_syll if kwargs.get('by_syll') else key_line\n",
    "        if not key in self._parses:\n",
    "            self.parse(force=force, **kwargs)\n",
    "        if not key in self._parses: return\n",
    "        \n",
    "        odf=self._parses[key]\n",
    "        if only_unbounded and ('parse_is_bounded' in set(odf.index.names) or 'parse_is_bounded' in set(odf.columns)):\n",
    "            #odf=odf[odf.parse_is_bounded==False]\n",
    "            odf=odf.query('parse_is_bounded==False')\n",
    "        if only_best and ('parse_rank' in set(odf.index.names) or 'parse_rank' in set(odf.columns)):\n",
    "            odf=odf.query('parse_rank==1')\n",
    "        \n",
    "        return odf\n",
    "\n",
    "    def best_parses(self, force=False, **kwargs):\n",
    "        return self.parses(force=force,only_best=True,**kwargs)\n",
    "    def all_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=False,**kwargs)\n",
    "    def unbounded_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e6dd0-8667-4d79-bff1-2a426e012df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c6364c6-1e4e-4d10-948e-9a6f3fb40a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Text('saintsbury/txt/en.addison.prose.Saintsbury.psgs_quoted.txt', prose=True, test='hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba54d14d-a35a-48bc-ab0b-fcc206f5f7bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_stanzas_str() missing 1 required positional argument: 'full_txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/jyzw5nyj1fnf0c_1czgsg2fc0000gn/T/ipykernel_51977/1624462467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanzas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/py/jyzw5nyj1fnf0c_1czgsg2fc0000gn/T/ipykernel_51977/3179564247.py\u001b[0m in \u001b[0;36mstanzas\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m##################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m### Stanzas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mstanzas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mto_stanzas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;31m### Paras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstanza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: to_stanzas_str() missing 1 required positional argument: 'full_txt'"
     ]
    }
   ],
   "source": [
    "t.stanzas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13cb098a-71e2-425d-91fc-b6b48f1fa2c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Text' object has no attribute 'first_line'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    392\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                                 \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__repr__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                             \u001b[0;32mreturn\u001b[0m \u001b[0m_repr_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_default_pprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;34m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;31m# Find newlines and replace them with p.break_()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/py/jyzw5nyj1fnf0c_1czgsg2fc0000gn/T/ipykernel_50097/3453788185.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\t'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'''<cadence.Text: {self.first_line} ({self.num_stanzas} stanza{\"s\" if self.num_stanzas>1 else \"\"}, {self.num_lines} line{\"s\" if self.num_lines>1 else \"\"})>'''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;31m#o='\\n'.join(l.strip() for l in o.split('\\n'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Text' object has no attribute 'first_line'"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68552ece-b431-4aad-bbe0-ece438fdb810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14bb6df-41b9-4173-ad56-52c01e453189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'This is a test']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945739f0-cf33-4f71-92d6-f459c3961ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.kwargs_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81390813-1478-4b78-b196-ed06658dd393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd08d9a62951c4de3cec93df06e5a8769682e2513316501195b5ad08e283a24e7b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
