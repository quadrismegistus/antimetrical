{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ecd93b1-4a57-4717-921d-fba48d082c2c",
   "metadata": {},
   "source": [
    "# Developing text objects further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d458e262-ffb6-4df5-a819-36328b99ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0,'/Users/ryan/github/cadence/')\n",
    "from cadence.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "652013e9-44e0-4a25-8986-b314b8fa78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Turning and turning in the widening gyre'\n",
    "txt=\"\"\"\n",
    "Turning and turning in the widening gyre. the falcon cannot hear the falconer;\n",
    "Things fall apart; the centre cannot hold;\n",
    "Mere anarchy is loosed upon the world. \n",
    "The blood-dimmed tide is loosed, and everywhere the ceremony of innocence is drowned;\n",
    "The best lack all conviction, while the worst   \n",
    "Are full of passionate intensity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d5bbe84-a2e1-4d95-bd6f-87429f1423d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nTurning and turning in the widening gyre.',\n",
       " 'the falcon cannot hear the falconer;\\nThings fall apart; the centre cannot hold;\\nMere anarchy is loosed upon the world.',\n",
       " 'The blood-dimmed tide is loosed, and everywhere the ceremony of innocence is drowned;\\nThe best lack all conviction, while the worst   \\nAre full of passionate intensity.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d258fff-1c95-4d0d-9a71-fc231cf569c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c9e91-1bb7-4cda-b610-91b2a93fa5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc53116c-9706-40f3-812a-21f1db91b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_stanzas_str(full_txt,sep=SEP_STANZA,**kwargs):\n",
    "    return [st.strip() for st in full_txt.strip().split(sep) if st.strip()]\n",
    "\n",
    "def to_lines_str(stanza_txt,sep=SEP_STANZA,**kwargs):\n",
    "    return [st.strip() for st in stanza_txt.strip().split(sep) if st.strip()]\n",
    "\n",
    "def to_sents_str(stanza_txt,**kwargs):\n",
    "    return list(nltk.sent_tokenize(stanza_txt))\n",
    "\n",
    "def limit_lineparts(linepart_toks,min_len=None,max_len=None):\n",
    "    if not min_len and not max_len: return [linepart_toks]\n",
    "\n",
    "    lp=[]\n",
    "    o=[]\n",
    "    for tok in reversed(linepart_toks):\n",
    "        lp.insert(0,tok)\n",
    "        if len(lp)>=max_len:\n",
    "            o.insert(0,lp)\n",
    "            lp=[]\n",
    "    if lp: o.insert(0,lp)\n",
    "    \n",
    "    return o\n",
    "    \n",
    "\n",
    "def to_lineparts_str(line_str,seps=SEPS_PHRASE,**kwargs):\n",
    "    lineparts=[]\n",
    "    linepart=[]\n",
    "    tokens=list(tokenize_nice(line_str))\n",
    "    for token in tokens:\n",
    "        pref,tok,suf = split_punct(token)        \n",
    "        is_pref_stopper=set(pref)&set(seps)\n",
    "        is_suf_stopper=set(suf)&set(seps)\n",
    "        \n",
    "        if is_pref_stopper:\n",
    "            lineparts.append(linepart)\n",
    "            linepart=[]\n",
    "        \n",
    "        linepart.append(token)\n",
    "        \n",
    "        if is_suf_stopper:\n",
    "            lineparts.append(linepart)\n",
    "            linepart=[]\n",
    "\n",
    "    # add if remaining\n",
    "    if linepart:\n",
    "        lineparts.append(linepart)\n",
    "        linepart=[]\n",
    "        \n",
    "    ## Further divide by max_len\n",
    "    o=[''.join(lpstr2) for lp_toks in lineparts for lpstr2 in limit_lineparts(lp_toks,**kwargs)]        \n",
    "    return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43eb5284-555e-4ebe-80cb-d32ae2fa8dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nTurning and turning in the widening gyre.',\n",
       " 'the falcon cannot hear the falconer;\\nThings fall apart; the centre cannot hold;\\nMere anarchy is loosed upon the world.',\n",
       " 'The blood-dimmed tide is loosed, and everywhere the ceremony of innocence is drowned;\\nThe best lack all conviction, while the worst   \\nAre full of passionate intensity.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0d0e8c6-97d5-4105-a3b1-a2c985feee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def to_lineparts_ld(\n",
    "        txt_or_fn_or_lpdf,\n",
    "        lang=DEFAULT_LANG,\n",
    "        progress=True,\n",
    "        incl_alt=INCL_ALT,\n",
    "        num_proc=DEFAULT_NUM_PROC,\n",
    "        linebreaks=False,\n",
    "        phrasebreaks=True,\n",
    "        verse=None,\n",
    "        prose=None,\n",
    "        min_len=MIN_WORDS_IN_PHRASE,\n",
    "        max_len=MAX_WORDS_IN_PHRASE,\n",
    "        seps=SEPS_PHRASE,\n",
    "        desc='Iterating over line scansions',\n",
    "        **kwargs):\n",
    "    \n",
    "    if type(txt_or_fn_or_lpdf) == pd.DataFrame:\n",
    "        odf=resetindex(txt_or_fn_or_lpdf)\n",
    "        if 'linepart_str' in set(odf.columns):\n",
    "            return odf\n",
    "        else:\n",
    "            raise Exception('Input is neither string or a linepart-df [result of lineparts()]')\n",
    "    \n",
    "    full_txt=to_txt(txt_or_fn_or_lpdf)\n",
    "    if full_txt is None: return\n",
    "    \n",
    "    if verse==True or prose==False:\n",
    "        linebreaks=True\n",
    "        phrasebreaks=False\n",
    "    elif prose==True or verse==False:\n",
    "        linebreaks=False\n",
    "        phrasebreaks=True\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    dfl=[]\n",
    "    to_lines_now = to_lines_str if linebreaks else to_sents_str\n",
    "    kwargs['lang']=lang\n",
    "    kwargs['incl_alt']=incl_alt\n",
    "    \n",
    "        \n",
    "    objs=[\n",
    "        dict(\n",
    "            stanza_i=stanza_i+1,\n",
    "            line_i=line_i+1,\n",
    "            linepart_i=linepart_i+1,\n",
    "            linepart_str=linepart_txt\n",
    "        )\n",
    "        for stanza_i,stanza_txt in enumerate(to_stanzas_str(full_txt))\n",
    "        for line_i,line_txt in enumerate(to_lines_now(stanza_txt))\n",
    "        for linepart_i,linepart_txt in enumerate(\n",
    "            to_lineparts_str(\n",
    "                line_txt,\n",
    "                seps=seps,\n",
    "                min_len=min_len,\n",
    "                max_len=max_len\n",
    "            ) if phrasebreaks else [line_txt]\n",
    "        )\n",
    "    ]\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7991df43-2d77-46af-b595-886df6126e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stanza_i': 1, 'line_i': 1, 'linepart_i': 1, 'linepart_str': 'hello world '}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_lineparts_ld('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41fa8559-6cd9-4cb4-8178-3ff1fee5dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_iter(df_or_txt_or_fn,num_proc=1,lim=None,progress=True,lineparts_ld=[],**kwargs):\n",
    "    if not lineparts_ld:\n",
    "        lineparts_ld=to_lineparts_ld(df_or_txt_or_fn,**kwargs)\n",
    "    iterr_o=pmap_iter(\n",
    "        do_scan_iter,\n",
    "        lineparts_ld,\n",
    "        progress=progress,\n",
    "        num_proc=num_proc,\n",
    "        desc='Scanning lines'\n",
    "    )\n",
    "    for i,odf in enumerate(iterr_o):\n",
    "        if lim and i>=lim: break\n",
    "        yield odf\n",
    "\n",
    "        \n",
    "def scan(txt_or_fn,**kwargs):\n",
    "    o=list(scan_iter(txt_or_fn,**kwargs))\n",
    "    return pd.concat(o) if len(o) else pd.DataFrame()\n",
    "\n",
    "def do_scan_iter(rowd,**kwargs):\n",
    "    lpstr=rowd['linepart_str']\n",
    "    odf=get_scansion(lpstr,**kwargs)\n",
    "    for k,v in rowd.items(): odf[k]=v\n",
    "    return setindex(odf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cffba42b-96db-4520-9dd2-547799f17c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for odf in scan_iter(txt,max_len=2): display(odf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eccc3930-bdc6-4fbe-9911-f6626ec4a9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning lines [x1]: 100%|███████████████████████████████████████████| 29/29 [00:00<00:00, 86.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>is_funcword</th>\n",
       "      <th>is_heavy</th>\n",
       "      <th>is_light</th>\n",
       "      <th>is_peak</th>\n",
       "      <th>is_stressed</th>\n",
       "      <th>is_trough</th>\n",
       "      <th>is_unstressed</th>\n",
       "      <th>linepart_num_monosyll</th>\n",
       "      <th>linepart_num_syll</th>\n",
       "      <th>prom_strength</th>\n",
       "      <th>prom_stress</th>\n",
       "      <th>prom_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanza_i</th>\n",
       "      <th>line_i</th>\n",
       "      <th>linepart_i</th>\n",
       "      <th>linepart_str</th>\n",
       "      <th>word_i</th>\n",
       "      <th>word_str</th>\n",
       "      <th>word_ipa_i</th>\n",
       "      <th>word_ipa</th>\n",
       "      <th>syll_i</th>\n",
       "      <th>syll_str</th>\n",
       "      <th>syll_ipa</th>\n",
       "      <th>syll_stress</th>\n",
       "      <th>syll_weight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"11\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">'tɛː.nɪŋ</th>\n",
       "      <th>1</th>\n",
       "      <th>Tur</th>\n",
       "      <th>'tɛː</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ning</th>\n",
       "      <th>nɪŋ</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">and turning</th>\n",
       "      <th>1</th>\n",
       "      <th>and</th>\n",
       "      <th>1</th>\n",
       "      <th>ænd</th>\n",
       "      <th>1</th>\n",
       "      <th>and</th>\n",
       "      <th>ænd</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">turning</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">'tɛː.nɪŋ</th>\n",
       "      <th>1</th>\n",
       "      <th>tur</th>\n",
       "      <th>'tɛː</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ning</th>\n",
       "      <th>nɪŋ</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">29</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">passionate intensity.</th>\n",
       "      <th>1</th>\n",
       "      <th>passionate</th>\n",
       "      <th>1</th>\n",
       "      <th>'pæ.ʃə.nət</th>\n",
       "      <th>3</th>\n",
       "      <th>nate</th>\n",
       "      <th>nət</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">intensity.</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">ɪn.'tɛn.sə.tiː</th>\n",
       "      <th>1</th>\n",
       "      <th>in</th>\n",
       "      <th>ɪn</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>ten</th>\n",
       "      <th>'tɛn</th>\n",
       "      <th>P</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>si</th>\n",
       "      <th>sə</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>ty.</th>\n",
       "      <th>tiː</th>\n",
       "      <th>U</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 is_funcword  ...  prom_weight\n",
       "stanza_i line_i linepart_i linepart_str           word_i word_str    word_ipa_i word_ipa       syll_i syll_str syll_ipa syll_stress syll_weight               ...             \n",
       "1        1      1          Turning                1      Turning     1          'tɛː.nɪŋ       1      Tur      'tɛː     P                                  0  ...          NaN\n",
       "                                                                                               2      ning     nɪŋ      U                                  0  ...          NaN\n",
       "                2          and turning            1      and         1          ænd            1      and      ænd      U                                  1  ...          NaN\n",
       "                                                  2      turning     1          'tɛː.nɪŋ       1      tur      'tɛː     P                                  0  ...          NaN\n",
       "                                                                                               2      ning     nɪŋ      U                                  0  ...          NaN\n",
       "...                                                                                                                                                      ...  ...          ...\n",
       "                29         passionate intensity.  1      passionate  1          'pæ.ʃə.nət     3      nate     nət      U                                  0  ...          NaN\n",
       "                                                  2      intensity.  1          ɪn.'tɛn.sə.tiː 1      in       ɪn       U                                  0  ...          NaN\n",
       "                                                                                               2      ten      'tɛn     P                                  0  ...          NaN\n",
       "                                                                                               3      si       sə       U                                  0  ...          NaN\n",
       "                                                                                               4      ty.      tiː      U                                  0  ...          NaN\n",
       "\n",
       "[93 rows x 12 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan(txt,max_len=2,linebreaks=True,phrasebreaks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34eea5c2-4ded-4302-8b61-72fc95e6797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Verse(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Poem(txt,**kwargs):\n",
    "    kwargs={**dict(verse=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def Prose(txt,**kwargs):\n",
    "    kwargs={**dict(prose=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "def FreeVerse(txt,**kwargs):\n",
    "    kwargs={**dict(linebreaks=True,phrasebreaks=True), **kwargs}\n",
    "    return Text(txt,**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# loading txt/strings\n",
    "def to_fn_txt(txt_or_fn):\n",
    "    # load txt\n",
    "    if type(txt_or_fn)==str and not '\\n' in txt_or_fn and os.path.exists(txt_or_fn):\n",
    "        fn=txt_or_fn\n",
    "        with open(fn,encoding='utf-8',errors='replace') as f:\n",
    "            txt=f.read()\n",
    "    else:\n",
    "        fn=''\n",
    "        txt=txt_or_fn\n",
    "    return (fn,txt.strip())\n",
    "\n",
    "\n",
    "### convenient objs\n",
    "def kwargs_key(kwargs,bad_keys={'num_proc','progress','desc'}):\n",
    "    return ', '.join(\n",
    "        f'{k}={v}'\n",
    "        for k,v in kwargs.items()\n",
    "        if k not in bad_keys\n",
    "    )\n",
    "    \n",
    "    \n",
    "### texts\n",
    "class Text(object):\n",
    "    def __init__(self,txt_or_fn,**kwargs):\n",
    "        \n",
    "        self._scans={}\n",
    "        self._parses={}\n",
    "        self._lineparts={}\n",
    "        self._num_lines=None\n",
    "        self._num_stanzas=None\n",
    "        self._infod={}\n",
    "        self._kwargs=kwargs\n",
    "        \n",
    "        ## Load texts\n",
    "        self.fn,self.txt=to_fn_txt(txt_or_fn)\n",
    "        \n",
    "    # def __repr__(self):\n",
    "    #     o=self.txt.split('\\n\\n')[0] if self.txt is not None else \"\"\n",
    "    #     o='\\t' + '\\n\\t'.join(l for l in o.split('\\n'))\n",
    "    #     o=f'''<cadence.Text: {self.first_line} ({self.num_stanzas} stanza{\"s\" if self.num_stanzas>1 else \"\"}, {self.num_lines} line{\"s\" if self.num_lines>1 else \"\"})>'''.strip()\n",
    "    #     #o='\\n'.join(l.strip() for l in o.split('\\n'))\n",
    "    #     return o\n",
    "    \n",
    "    def kwargs(self,**kwargs):\n",
    "        return {**self._kwargs, **kwargs}\n",
    "    \n",
    "    def get_kwargs_key(self,**kwargs):\n",
    "        return kwargs_key(self.kwargs(**kwargs))\n",
    "\n",
    "\n",
    "    \n",
    "    ##################################################################\n",
    "    ### Stanzas\n",
    "    def stanzas(self,txt='',**kwargs):\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return to_stanzas_str(txt if txt else self.txt,**kwargs)    \n",
    "\n",
    "    ##################################################################\n",
    "    ### Lines\n",
    "    \n",
    "    def lines(self,txt='',linebreaks=False,prose=False,**kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        to_lines_now = to_lines_str if kwargs.get('linebreaks') or kwargs.get('verse') else to_sents_str\n",
    "        return [\n",
    "            l\n",
    "            for stanza_str in self.stanzas(txt,**kwargs)\n",
    "            for l in to_lines_now(stanza_str, **kwargs)\n",
    "        ]\n",
    "    \n",
    "    def sentences(self,txt='',**kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return [\n",
    "            lp\n",
    "            for line_str in self.lines(txt,**kwargs)\n",
    "            for lp in to_sents_str(line_str, **kwargs)\n",
    "        ]\n",
    "\n",
    "\n",
    "    ##################################################################\n",
    "    ### LINEPARTS\n",
    "    \n",
    "    ### Lineparts\n",
    "    def lineparts(self, txt='', **kwargs):\n",
    "        if not txt: txt=self.txt\n",
    "        kwargs=self.kwargs(**kwargs)\n",
    "        return [\n",
    "            lp\n",
    "            for line_str in self.lines(txt,**kwargs)\n",
    "            for lp in to_lineparts_str(line_str, **kwargs)\n",
    "        ]        \n",
    "    \n",
    "    ##################################################################\n",
    "    ### SCANS\n",
    "    \n",
    "    def scan(self, force=False, **kwargs):\n",
    "        key=self.get_kwargs_key(**kwargs)\n",
    "        if force or not key in self._scans:\n",
    "            self._scans[key]=scan(self.txt,**kwargs)\n",
    "        return self._scans[key]\n",
    "\n",
    "    \n",
    "    \n",
    "    ##################################################################\n",
    "    ### PARSE\n",
    "    \n",
    "    def parse(self,\n",
    "            force=False,\n",
    "            verbose=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs['verbose']=verbose\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        if force or not (key_syll in self._parses) or (not key_line in self._parses):\n",
    "            self._parses[key_syll]=parse(self.txt, **kwargs_syll)\n",
    "            self._parses[key_line]=to_lines(self._parses[key_syll])\n",
    "        elif kwargs.get('verbose',True):\n",
    "            for li,linedf in sorted(self._parses[key_syll].reset_index().groupby(['stanza_i','line_i'])):\n",
    "                display(show_parse(linedf))\n",
    "\n",
    "        self.infod=info_parses(self._parses[key_line])\n",
    "        if verbose: printm(show_info_parses(self.infod))\n",
    "                \n",
    "        \n",
    "    def parses(self,\n",
    "            force=True,\n",
    "            only_best=False,\n",
    "            only_unbounded=True,\n",
    "            **kwargs):\n",
    "        kwargs={**self.kwargs, **kwargs}\n",
    "        kwargs_line={**self.kwargs, **kwargs, **{'by_syll':False}}\n",
    "        kwargs_syll={**self.kwargs, **kwargs, **{'by_syll':True}}\n",
    "        key_line=kwargs_key(kwargs_line)\n",
    "        key_syll=kwargs_key(kwargs_syll)\n",
    "        key=key_syll if kwargs.get('by_syll') else key_line\n",
    "        if not key in self._parses:\n",
    "            self.parse(force=force, **kwargs)\n",
    "        if not key in self._parses: return\n",
    "        \n",
    "        odf=self._parses[key]\n",
    "        if only_unbounded and ('parse_is_bounded' in set(odf.index.names) or 'parse_is_bounded' in set(odf.columns)):\n",
    "            #odf=odf[odf.parse_is_bounded==False]\n",
    "            odf=odf.query('parse_is_bounded==False')\n",
    "        if only_best and ('parse_rank' in set(odf.index.names) or 'parse_rank' in set(odf.columns)):\n",
    "            odf=odf.query('parse_rank==1')\n",
    "        \n",
    "        return odf\n",
    "\n",
    "    def best_parses(self, force=False, **kwargs):\n",
    "        return self.parses(force=force,only_best=True,**kwargs)\n",
    "    def all_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=False,**kwargs)\n",
    "    def unbounded_parses(self, force=False,**kwargs):\n",
    "        return self.parses(force=force,only_best=False,only_unbounded=True,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e6dd0-8667-4d79-bff1-2a426e012df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c6364c6-1e4e-4d10-948e-9a6f3fb40a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Text('saintsbury/txt/en.addison.prose.Saintsbury.psgs_quoted.txt', prose=True, test='hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3811jvsc74a57bd08d9a62951c4de3cec93df06e5a8769682e2513316501195b5ad08e283a24e7b2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
